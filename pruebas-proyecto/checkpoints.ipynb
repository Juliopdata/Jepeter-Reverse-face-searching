{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    img_data_list=[]\n",
    "    data_path = path\n",
    "\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        for img in img_list:\n",
    "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "            input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "            #input_img_resize=cv2.resize(input_img,(64,64))\n",
    "            input_img_resize = face_cascade.detectMultiScale(input_img, 1.1, 3)\n",
    "            print (input_img_resize)\n",
    "            x,y,w,h = input_img_resize[0]\n",
    "            input_img_resize = input_img_resize[y:y+h,x:x+w]\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    #img_data = img_data.astype('float32')\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = load_dataset(\"../data/lfw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(X).to_csv(\"/path/to/croppedphotos.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "def build_autoencoder(img_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(img_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size,)))\n",
    "    decoder.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "    decoder.add(Reshape(img_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X.shape[1:]\n",
    "encoder, decoder = build_autoencoder(IMG_SHAPE, 500)\n",
    "\n",
    "inp = Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = Model(inp,reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='Checkpoint_{epoch:02d}_{val_loss:.2f}'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x=X_train, y=X_train, epochs=20,\n",
    "                validation_data=[X_test, X_test], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment=time.localtime()\n",
    "name='Model{}.h5'.format(autoencoder.history.history[\"val_loss\"][-1],moment[2],moment[3],moment[4])\n",
    "autoencoder.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_json = autoencoder.to_json()\n",
    "with open(name+'.json', \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "autoencoder.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    # img[None] will have shape of (1, 32, 32, 3) which is the same as the model input\n",
    "    code = encoder.predict(img[None])[0]\n",
    "    reco = decoder.predict(code[None])[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    show_image(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    show_image(reco)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(6):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_dataset(\"../data/fotop/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "im = cv2.imread(\"../data/fotop/Cris/5.jpeg\")\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    img = X[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
