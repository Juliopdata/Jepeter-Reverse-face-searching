{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, InputLayer\n",
    "from keras.models import Model, model_from_json, load_model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from align import AlignDlib\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRS_NAME = \"./data/lfw_attributes.txt\"\n",
    "\n",
    "IMAGES_NAME = \"./data/lfw-deepfunneled.tgz\"\n",
    "\n",
    "RAW_IMAGES_NAME = \"./data/lfw.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(raw_bytes):\n",
    "    img = cv2.imdecode(np.asarray(bytearray(raw_bytes), dtype=np.uint8), 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(\n",
    "        use_raw=False,\n",
    "        dx=80, dy=80,\n",
    "        dimx=45, dimy=45):\n",
    "\n",
    "    # Read attrs\n",
    "    df_attrs = pd.read_csv(ATTRS_NAME, sep='\\t', skiprows=1)\n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:, :-1].values, columns=df_attrs.columns[1:])\n",
    "    imgs_with_attrs = set(map(tuple, df_attrs[[\"person\", \"imagenum\"]].values))\n",
    "\n",
    "    # Read photos\n",
    "    all_photos = []\n",
    "    photo_ids = []\n",
    "\n",
    "    with tarfile.open(RAW_IMAGES_NAME if use_raw else IMAGES_NAME) as f:\n",
    "        for m in f.getmembers():\n",
    "            # Only process image files from the compressed data\n",
    "            if m.isfile() and m.name.endswith(\".jpg\"):\n",
    "                # Prepare image\n",
    "                img = decoder(f.extractfile(m).read())\n",
    "\n",
    "                # Crop only faces and resize it\n",
    "                img = img[dy:-dy, dx:-dx]\n",
    "                img = cv2.resize(img, (dimx, dimy))\n",
    "\n",
    "                # Parse person and append it to the collected data\n",
    "                foldername = os.path.split(m.name)\n",
    "                filename = os.path.split(m.name)[-1]\n",
    "                fname_splitted = filename[:-4].replace('_', ' ').split()\n",
    "                person_id = ' '.join(fname_splitted[:-1])\n",
    "                photo_number = int(fname_splitted[-1])\n",
    "                if (person_id, photo_number) in imgs_with_attrs:\n",
    "                    all_photos.append(img)\n",
    "                    photo_ids.append({'Person': person_id, 'imagenum': photo_number, 'Array': img, \"File\": filename, \"Path\": foldername })\n",
    "\n",
    "    photo_ids = pd.DataFrame(photo_ids)\n",
    "    all_photos = np.stack(all_photos).astype('uint8')\n",
    "    all_photos = all_photos.astype('float32') / 255.0 - 0.5\n",
    "\n",
    "    # Preserve photo_ids order!\n",
    "    #all_attrs = photo_ids.merge(df_attrs, on=('person', 'imagenum'))\n",
    "\n",
    "    return all_photos, photo_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply The Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-81b212dc2c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphotosDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_lfw_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-583f594d0fc4>\u001b[0m in \u001b[0;36mload_lfw_dataset\u001b[0;34m(use_raw, dx, dy, dimx, dimy)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# Prepare image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# Crop only faces and resize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, photosDf = load_lfw_dataset(use_raw=True, dimx=128, dimy=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(img_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(img_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size,)))\n",
    "    decoder.add(Dense(np.prod(img_shape)))\n",
    "    decoder.add(Reshape(img_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X.shape[1:]\n",
    "encoder, decoder = build_autoencoder(IMG_SHAPE, 1000)\n",
    "\n",
    "inp = Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = Model(inp,reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='Checkpoint_{epoch:02d}_{val_loss:.2f}'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x=X, y=X, epochs=20\n",
    "                )\n",
    "#validation_data=[X_test, X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af6c1ebf9467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmoment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Model1{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "moment=time.localtime()\n",
    "name='Model1{}.h5'.format(autoencoder.history.history[\"val_loss\"][-1],moment[2],moment[3],moment[4])\n",
    "autoencoder.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights to disk\n"
     ]
    }
   ],
   "source": [
    "encoder.save_weights(\"./data/models/encoderweights128.h5\")\n",
    "decoder.save_weights(\"./data/models/decoderweights128.h5\")\n",
    "autoencoder.save_weights('./data/models/autoencoderweights128.h5')\n",
    "print(\"Saving weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"./data/models/autoencoder32_save\", overwrite=True)\n",
    "encoder.save(\"./data/models/encoder32_save\", overwrite=True)\n",
    "decoder.save(\"./data/models/decoder32_save\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = autoencoder.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0e5ca4c85661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./graphics/model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Check Reconstructed Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e787014ab5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize(img,encoder,decoder,):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    # img[None] will have shape of (1, 32, 32, 3) which is the same as the model input\n",
    "    code = encoder.predict(img[None])[0]\n",
    "    reco = decoder.predict(code[None])[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    show_image(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    show_image(reco)\n",
    "   \n",
    "    plt.show()\n",
    "for i in range(5):\n",
    "    img = X[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to test the model with friends photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    img_data_list=[]\n",
    "    #data_path = path       \n",
    "    input_img=cv2.imread(path)\n",
    "    input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "    #input_img_resize=cv2.resize(input_img,(64,64))\n",
    "    faces = face_cascade.detectMultiScale(input_img, 1.1, 3)\n",
    "    print (faces[0])\n",
    "    #input_img_resize=cv2.resize(input_img,(128,128))\n",
    "    x,y,w,h = faces[0]\n",
    "    print(x,y,w,h)\n",
    "    face = input_img[y:y+h,x:x+w]\n",
    "    face=cv2.resize(face,(128,128))\n",
    "    #face=face / 255.0 - 0.5\n",
    "    #face = np.expand_dims(faces, axis=1)\n",
    "    img_data_list.append(face)\n",
    "\n",
    "    img_data = np.stack(img_data_list).astype('uint8')\n",
    "    #img_data = img_data.astype('float32')\n",
    "    return img_data/ 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137 152 299 299]\n",
      "137 152 299 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_dataset(\"./data/fotop/Alex/alex1.jpg\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7da41d7b61b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    img = X[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
